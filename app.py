# app.py

import streamlit as st
import os
import pandas as pd
import time
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.document_loaders import PyPDFLoader, CSVLoader
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import ConversationalRetrievalChain
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent
from langchain.memory import ConversationBufferMemory

# --- 1. í™˜ê²½ ì„¤ì • ë° API í‚¤ ë¡œë“œ ---

st.set_page_config(page_title="ë°”ì´ë¸Œì½”ë”© AI íŠœí„° ë´‡", page_icon="ğŸ¤–")
st.title("ğŸ¤– ë°”ì´ë¸Œì½”ë”© AI íŠœí„° ë´‡")
st.markdown("Apps Scriptì™€ Geminië¥¼ í™œìš©í•œ ì•„ì´ë””ì–´ë¥¼ ì ê²€í•´ ë“œë¦½ë‹ˆë‹¤.")
st.markdown("---")

# Streamlit secretsì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
try:
    OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
    os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY
except KeyError:
    st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit secretsì— ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    st.stop()

# --- 2. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ (RAG) ---
# ë°ì´í„° ë¡œë“œ, ì „ì²˜ë¦¬, ë²¡í„°í™”ëŠ” ë¦¬ì†ŒìŠ¤ë¥¼ ë§ì´ ì‚¬ìš©í•˜ë¯€ë¡œ ìºì‹œ ì²˜ë¦¬í•©ë‹ˆë‹¤.

# ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì •
PDF_FILE_PATH = os.path.join("data", "course_handout.pdf")
CSV_FILE_PATH = os.path.join("data", "instructor_feedback.csv")

@st.cache_resource(show_spinner="ğŸ—‚ï¸ ì±—ë´‡ ë‘ë‡Œ(ì§€ì‹) ë¡œë”© ì¤‘...")
def load_and_build_knowledge_base():
    """
    data í´ë”ì—ì„œ PDFì™€ CSV íŒŒì¼ì„ ë¡œë“œí•˜ê³  FAISS ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    documents = []
    
    # PDF ë¡œë“œ
    try:
        pdf_loader = PyPDFLoader(PDF_FILE_PATH)
        documents.extend(pdf_loader.load())
    except Exception as e:
        st.warning(f"PDF íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}. 'data/course_handout.pdf' íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

    # í…ìŠ¤íŠ¸ ë¶„í• 
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    split_docs = text_splitter.split_documents(documents)
    
    # ì„ë² ë”© ë° ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
    embeddings = OpenAIEmbeddings()
    try:
        vector_store = FAISS.from_documents(split_docs, embeddings)
    except Exception as e:
        st.error(f"ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì‹¤íŒ¨: {e}. PDF ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë¹„ì–´ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return None, None

    # CSV ë¡œë“œ (Pandas Agent ìš©)
    try:
        df = pd.read_csv(CSV_FILE_PATH)
    except Exception as e:
        st.warning(f"CSV íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}. 'data/instructor_feedback.csv' íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        return vector_store, None

    return vector_store, df

# --- 3. LangChain ì—ì´ì „íŠ¸ ë° ì²´ì¸ ìƒì„± ---

# 1) RAG (PDF) ë° 2) Pandas (CSV) ë¡œë“œ
vector_store, df = load_and_build_knowledge_base()

# LLM ëª¨ë¸ ì •ì˜
llm = ChatOpenAI(model_name="gpt-4o", temperature=0)

# 3) ëŒ€í™” ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
# session_stateì— ë©”ëª¨ë¦¬ ì €ì¥
if "chat_memory" not in st.session_state:
    st.session_state.chat_memory = ConversationBufferMemory(
        memory_key="chat_history", 
        return_messages=True
    )
memory = st.session_state.chat_memory

# 4) RAG ì²´ì¸ ìƒì„± (PDF ë¬¸ì„œ ê²€ìƒ‰ìš©)
# ConversationalRetrievalChain: RAG + ë©”ëª¨ë¦¬
pdf_chain = None
if vector_store:
    pdf_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vector_store.as_retriever(),
        memory=memory,
        chain_type="stuff",
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì¡°ì • ê°€ëŠ¥)
        combine_docs_chain_kwargs={
            "prompt": st.chat_input(
                "ë‹¹ì‹ ì€ ë°”ì´ë¸Œì½”ë”© ì—°ìˆ˜ íŠœí„°ì…ë‹ˆë‹¤. êµì‚¬ì˜ ì§ˆë¬¸ì— ëŒ€í•´ **ë°˜ë“œì‹œ 'ì°¸ê³  ìë£Œ'ì— ê·¼ê±°í•´ì„œ** ì „ë¬¸ì ì´ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.\n"
                "ìë£Œì— ì—†ëŠ” ë‚´ìš©ì€ 'í•™ìŠµ ìë£Œì— ì—†ëŠ” ë‚´ìš©ì…ë‹ˆë‹¤'ë¼ê³  ë‹µí•˜ì„¸ìš”.\n\n"
                "ì°¸ê³  ìë£Œ:\n{context}\n\n"
                "ì§ˆë¬¸: {question}"
            )
        }
    )

# 5) Pandas DataFrame ì—ì´ì „íŠ¸ ìƒì„± (CSV í”¼ë“œë°± ê²€ìƒ‰ìš©)
pandas_agent = None
if df is not None:
    pandas_agent = create_pandas_dataframe_agent(
        llm,
        df,
        verbose=True, # ì—ì´ì „íŠ¸ ì‘ë™ ê³¼ì •ì„ ë³¼ ìˆ˜ ìˆìŒ (ë””ë²„ê¹…ìš©)
        allow_dangerous_code=True, # CSV ë¶„ì„ì„ ìœ„í•´ Python ì½”ë“œ ì‹¤í–‰ í—ˆìš©
        agent_type="openai-functions",
        # ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸ (ê°€ì¥ ì¤‘ìš”)
        prompt=(
            "ë‹¹ì‹ ì€ 'ë°”ì´ë¸Œì½”ë”© ê°•ì‚¬ í”¼ë“œë°±' CSV ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” AIì…ë‹ˆë‹¤. "
            "ì´ ë°ì´í„°ëŠ” êµì‚¬ë“¤ì˜ ì•„ì´ë””ì–´ì™€ ê·¸ì— ëŒ€í•œ ê°•ì‚¬ì˜ í”¼ë“œë°±ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. "
            "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ì´ ë°ì´í„°ì™€ ê´€ë ¨ ìˆëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”. "
            "CSVì˜ 'idea_summary' ì»¬ëŸ¼ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì§ˆë¬¸ê³¼ ê°€ì¥ ìœ ì‚¬í•œ í–‰ì„ ì°¾ìœ¼ì„¸ìš”. "
            "ì°¾ì•˜ë‹¤ë©´, í•´ë‹¹ í–‰ì˜ 'feasibility_apps_script'(êµ¬í˜„ê°€ëŠ¥ì„±), 'instructor_feedback'(ê°•ì‚¬í”¼ë“œë°±), 'alternative_suggestion'(ëŒ€ì•ˆ)ì„ **ê·¸ëŒ€ë¡œ** ì¸ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”."
        )
    )

# --- 4. Streamlit ì±—ë´‡ UI ë¡œì§ ---

# 1) ì„¸ì…˜ ìƒíƒœì— ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ì–´ë–¤ ì•„ì´ë””ì–´ë¥¼ êµ¬ìƒ ì¤‘ì´ì‹ ê°€ìš”?"}]

# 2) ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 3) ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if prompt := st.chat_input("ì•„ì´ë””ì–´ì— ëŒ€í•´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”..."):
    # 4) ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 5) ì±—ë´‡ ë‹µë³€ ìƒì„±
    with st.chat_message("assistant"):
        response_content = ""
        # 5-1: ë¨¼ì € Pandas ì—ì´ì „íŠ¸(CSV)ì—ê²Œ ì§ˆë¬¸
        try:
            if pandas_agent:
                with st.spinner("ğŸ”„ ê°•ì‚¬ í”¼ë“œë°±ì„ í™•ì¸í•˜ëŠ” ì¤‘..."):
                    # "agent_scratchpad"ëŠ” ì—ì´ì „íŠ¸ì˜ ìƒê°ì„ ì €ì¥í•˜ëŠ” ì„ì‹œ ê³µê°„ì…ë‹ˆë‹¤.
                    # chat_historyë¥¼ í¬í•¨í•˜ì—¬ ì§ˆë¬¸ì„ ì „ë‹¬í•©ë‹ˆë‹¤.
                    agent_response = pandas_agent.invoke({
                        "input": f"ì‚¬ìš©ì ì§ˆë¬¸: {prompt}\n\nëŒ€í™” ê¸°ë¡:\n{st.session_state.chat_memory.chat_history.messages}",
                    })
                    response_content = agent_response["output"]
            
            # 5-2: CSVì—ì„œ ìœ ì˜ë¯¸í•œ ë‹µì„ ëª» ì°¾ì•˜ì„ ê²½ìš°, RAG ì²´ì¸(PDF)ì—ê²Œ ì§ˆë¬¸
            # (ê°„ë‹¨í•œ ë¡œì§: Pandasê°€ ë„ˆë¬´ ì§§ì€ ë‹µë³€ì„ í–ˆê±°ë‚˜, 'ëª¨ë¥´ê² ë‹¤'ê³  í–ˆì„ ë•Œ)
            if not response_content or len(response_content) < 50 or "ëª¨ë¥´ê² ë‹¤" in response_content:
                if pdf_chain:
                    with st.spinner("ğŸ“š ì—°ìˆ˜ ìë£Œë¥¼ ê²€ìƒ‰í•˜ëŠ” ì¤‘..."):
                        # RAG ì²´ì¸ì€ ë©”ëª¨ë¦¬ë¥¼ ìë™ìœ¼ë¡œ ì°¸ì¡°í•©ë‹ˆë‹¤.
                        pdf_response = pdf_chain.invoke({"question": prompt})
                        response_content = pdf_response["answer"]
                else:
                    response_content = "ì£„ì†¡í•©ë‹ˆë‹¤, í˜„ì¬ PDF ì—°ìˆ˜ ìë£Œë¥¼ ì°¸ì¡°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
        except Exception as e:
            st.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            response_content = "ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ì„ ì²˜ë¦¬í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."

        # 5-3: ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼ë¡œ ë‹µë³€ í‘œì‹œ
        message_placeholder = st.empty()
        full_response = ""
        for chunk in response_content.split():
            full_response += chunk + " "
            time.sleep(0.05)  # ë”œë ˆì´
            message_placeholder.markdown(full_response + "â–Œ")
        message_placeholder.markdown(full_response)
    
    # 6) ì±—ë´‡ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì— ì €ì¥
    st.session_state.messages.append({"role": "assistant", "content": full_response})
